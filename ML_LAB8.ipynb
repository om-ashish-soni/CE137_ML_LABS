{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOzbjvU3TgT0u60gJfGcEWN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Implementation of stacking , with max voting as classification model\n"],"metadata":{"id":"ZWHGdlLy3vWc"}},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvnZwvsM3sRh","executionInfo":{"status":"ok","timestamp":1675156604711,"user_tz":-330,"elapsed":3,"user":{"displayName":"CE137_Om_Soni","userId":"00290265016344326683"}},"outputId":"bc36399f-6835-4762-cde0-a334ceb32da5"},"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 1 1 1 0 0]\n","accuracy :  0.7142857142857143\n"]}],"source":["# 20 minutes\n","from sklearn import preprocessing\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB,CategoricalNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score   \n","\n","def max_voting(output):\n","  votes={}\n","  for elem in output:\n","    if elem in votes:\n","      votes[elem]+=1\n","    else :\n","      votes[elem]=1\n","  \n","  final_output=-1\n","  max_votes=-1\n","  for elem in votes:\n","    if max_votes<votes[elem]:\n","      max_votes=votes[elem]\n","      final_output=elem\n","      pass\n","    pass\n","  print(votes)\n","  return final_output,max_votes\n","  pass\n","\n","def get_data_set():\n","  weather = ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy','Rainy', 'Overcast','Sunny', 'Sunny', 'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy']\n","  temp = ['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n","  play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n","  le=preprocessing.LabelEncoder()\n","  weather_encoded=le.fit_transform(weather)\n","  temp_encoded=le.fit_transform(temp)\n","  play_encoded=le.fit_transform(play)\n","  features=tuple(zip(weather_encoded,temp_encoded))\n","  return features,play_encoded\n","  pass\n","\n","def get_individual_classifiers(x_train,y_train,no_of_models=10):\n","  individual_classifiers=[]\n","  for _ in range(no_of_models):\n","    \n","    new_model=CategoricalNB(alpha=1)\n","    new_model.fit(x_train,y_train)\n","    individual_classifiers.append(new_model)\n","    pass\n","  return individual_classifiers\n","  pass\n","\n","def individual_predict(individual_classifiers,input):\n","  output=[]\n","  for classifier in individual_classifiers:\n","    curr_output=list(classifier.predict(input))\n","    output=output+curr_output\n","    pass\n","  return output\n","  pass\n","\n","def get_meta_classifier(x,y):\n","  individual_classifiers=get_individual_classifiers(x_train,y_train)\n","  output=individual_predict(individual_classifiers,x)\n","  meta_x=output\n","  meta_y=[]\n","  div=len(meta_x)//len(x)\n","  for _ in range(div):\n","    meta_y=meta_y+list(y)\n","  meta_classifier=LogisticRegression(random_state=0).fit(x, y)\n","  return meta_classifier\n","  pass\n","\n","def get_accuracy(y_pred,y_test):\n","  \n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","\n","x,y=get_data_set()\n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50)\n","meta_classifier=get_meta_classifier(x_train,y_train)\n","\n","y_pred=meta_classifier.predict(x_test)\n","print(y_pred)\n","print(\"accuracy : \",get_accuracy(y_pred,y_test))\n","# x_1,y_1=individual_predict(individual_classifiers,[[1,2]])\n","# print(x_1,y_1)\n","\n"]},{"cell_type":"markdown","source":["# stacking using regression and low diabetes database"],"metadata":{"id":"t1onSksYHdjk"}},{"cell_type":"code","source":["# 20 minutes\n","from sklearn import preprocessing\n","from sklearn.naive_bayes import GaussianNB, MultinomialNB,CategoricalNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score   \n","from sklearn.datasets import load_diabetes\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error\n","\n","# def max_voting(output):\n","#   votes={}\n","#   for elem in output:\n","#     if elem in votes:\n","#       votes[elem]+=1\n","#     else :\n","#       votes[elem]=1\n","  \n","#   final_output=-1\n","#   max_votes=-1\n","#   for elem in votes:\n","#     if max_votes<votes[elem]:\n","#       max_votes=votes[elem]\n","#       final_output=elem\n","#       pass\n","#     pass\n","#   print(votes)\n","#   return final_output,max_votes\n","#   pass\n","\n","def get_data_set():\n","  import pandas as pd\n","  dataset=load_diabetes()\n","  x=dataset.data\n","  y=dataset.target\n","  return x,y\n","  pass\n","\n","def get_individual_classifiers(x_train,y_train,no_of_models=10):\n","  individual_classifiers=[]\n","  for _ in range(no_of_models):\n","    new_model=LinearRegression()\n","    new_model.fit(x_train,y_train)\n","    individual_classifiers.append(new_model)\n","    pass\n","  return individual_classifiers\n","  pass\n","\n","def individual_predict(individual_classifiers,input):\n","  output=[]\n","  for classifier in individual_classifiers:\n","    curr_output=list(classifier.predict(input))\n","    output=output+curr_output\n","    pass\n","  return output\n","  pass\n","\n","def get_meta_classifier(x,y):\n","  individual_classifiers=get_individual_classifiers(x_train,y_train)\n","  output=individual_predict(individual_classifiers,x)\n","  meta_x=output\n","  meta_y=[]\n","  div=len(meta_x)//len(x)\n","  for _ in range(div):\n","    meta_y=meta_y+list(y)\n","  meta_classifier=LinearRegression().fit(x, y)\n","  return meta_classifier\n","  pass\n","\n","def get_accuracy(y_pred,y_test):\n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","def get_mse(y_pred,y_test):\n","  return mean_squared_error(y_pred,y_test)\n","  pass\n","\n","x,y=get_data_set()\n","# print(x,y)\n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50)\n","meta_classifier=get_meta_classifier(x_train,y_train)\n","y_pred=meta_classifier.predict(x_test)\n","print(\"mse loss : \",get_mse(y_pred,y_test))\n","# x_1,y_1=individual_predict(individual_classifiers,[[1,2]])\n","# print(x_1,y_1)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5TVM7Q5Hg-V","executionInfo":{"status":"ok","timestamp":1675157660475,"user_tz":-330,"elapsed":5,"user":{"displayName":"CE137_Om_Soni","userId":"00290265016344326683"}},"outputId":"16803b8f-11ac-4a41-fd13-49ec581b1783"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["mse loss :  2679.3209640213354\n"]}]},{"cell_type":"markdown","source":["# Adaboost classifier"],"metadata":{"id":"A34pWSkl8BXs"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score   \n","from sklearn.datasets import load_breast_cancer\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.metrics import confusion_matrix\n","\n","def get_data_set():\n","  import pandas as pd\n","  dataset=load_breast_cancer()\n","  x=dataset.data\n","  y=dataset.target\n","  return x,y\n","  pass\n","\n","def get_classifier(x,y):\n","  return AdaBoostClassifier().fit(x,y)\n","\n","def get_accuracy(y_pred,y_test):\n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","def print_classification_report(y_pred,y_test):\n","  print(\"confusion matrix of addboostclassification\")\n","  cmat=confusion_matrix(y_test,y_pred)\n","  print(cmat)\n","  pass\n","x,y=get_data_set()\n","# print(x,y)\n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50)\n","classifier=get_classifier(x_train,y_train)\n","y_pred=classifier.predict(x_test)\n","print(\"accuracy : \",get_accuracy(y_pred,y_test))\n","print_classification_report(y_test,y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-M1xJhAhL1g6","executionInfo":{"status":"ok","timestamp":1675158442107,"user_tz":-330,"elapsed":689,"user":{"displayName":"CE137_Om_Soni","userId":"00290265016344326683"}},"outputId":"92823a0c-3a7f-420e-ba55-72f1989ab431"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy :  0.9789473684210527\n","confusion matrix of addboostclassification\n","[[103   2]\n"," [  4 176]]\n"]}]},{"cell_type":"markdown","source":["# Use StackingClassifier from sklearn to implement the same on cancer dataset. \n","Bagging and RandomForest"],"metadata":{"id":"WqBBSmVsOefs"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score   \n","from sklearn.datasets import load_breast_cancer\n","from sklearn.metrics import confusion_matrix\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import BaggingClassifier\n","\n","def get_data_set():\n","  import pandas as pd\n","  dataset=load_breast_cancer()\n","  x=dataset.data\n","  y=dataset.target\n","  return x,y\n","  pass\n","\n","def get_classifier(x,y):\n","  return BaggingClassifier().fit(x,y)\n","\n","def get_accuracy(y_pred,y_test):\n","  return accuracy_score(y_pred,y_test)\n","  pass\n","\n","def print_classification_report(y_pred,y_test):\n","  print(\"confusion matrix of bagging on descision tree classifier : \")\n","  cmat=confusion_matrix(y_test,y_pred)\n","  print(cmat)\n","  pass\n","\n","x,y=get_data_set()\n","# print(x,y)\n","x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=137,test_size=0.50)\n","classifier=get_classifier(x_train,y_train)\n","y_pred=classifier.predict(x_test)\n","print(\"accuracy : \",get_accuracy(y_pred,y_test))\n","print_classification_report(y_test,y_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NLk_eGPJOiHH","executionInfo":{"status":"ok","timestamp":1675159070985,"user_tz":-330,"elapsed":403,"user":{"displayName":"CE137_Om_Soni","userId":"00290265016344326683"}},"outputId":"6766acf4-2afc-44ef-d99a-4b4bfaf0c9bd"},"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy :  0.9438596491228071\n","confusion matrix of bagging on descision tree classifier : \n","[[100   9]\n"," [  7 169]]\n"]}]},{"cell_type":"markdown","source":["# Exercise : Try Adaboost Regression on concrete_data.csv."],"metadata":{"id":"EkXHPxOoQxu1"}}]}